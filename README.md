# auto_speaker

このプロジェクトは、音声を録音し、Whisperを使ってテキストに変換し、GPT-4にテキストを問い合わせ、EPDにレスポンスを表示し、テキスト読み上げAPIを使ってレスポンスを読み上げる自動スピーカーシステムです。

## 説明

このプロジェクトには、以下のコンポーネントが含まれています。

- `main.py`: アプリケーションのメインエントリーポイントです。音声を録音し、テキストに変換し、GPT-4に問い合わせ、EPDにレスポンスを表示し、テキスト読み上げAPIを使ってレスポンスを読み上げるプロセス全体を調整します。
- `api`: OpenAIのGPT-4およびTTSサービスとやり取りするためのAPIエンドポイントが含まれています。
    - `chat.py`: OpenAI GPT-4 APIとの通信を処理します。テキストプロンプトを入力として受け取り、GPT-4からのレスポンスを返します。また、その後のクエリのコンテキストを提供するために、会話履歴を保持します。ペルソナは、知識が豊富で、親しみやすく、親切な大阪在住の女性で、大阪弁で応答します。
    - `tts_voice.py`: OpenAI TTS APIを使用して、テキストを音声に変換します。テキスト文字列を入力として受け取り、音声ファイルを生成し、ユーザーに再生します。
- `display`: EPD（電子ペーパーディスプレイ）へのテキスト表示を管理します。
    - `epd_display.py`: EPDにテキストを表示するための関数が含まれています。表示に合わせてテキストを折り返し、日本語の文字を適切にレンダリングするために日本語フォントを使用します。
- `voice`: 音声の録音と文字起こしを処理します。
    - `get_voice.py`: マイクから音声を録音し、音声の開始と終了を検出し、Whisperを使用して音声をテキストに変換します。しきい値を使用して音声の開始と終了を判断し、録音された音声をWAVファイルに保存します。次に、subprocessを使用してWhisper CLIを実行し、音声をテキストに変換します。

## 依存関係

- `openai`: GPT-4およびTTSサービスにアクセスするためのOpenAI APIクライアント。
- `sounddevice`: マイクから音声を録音するため。
- `numpy`: 数値データ処理のため。
- `wave`: 音声データをWAVファイルに保存するため。
- `subprocess`: Whisper CLIを実行するため。
- `requests`: OpenAI APIにHTTPリクエストを送信するため。
- `simpleaudio`: 音声ファイルを再生するため。
- `pydub`: MP3ファイルをWAVファイルに変換するため。
- `PIL (Pillow)`: 画像処理とEPDへのテキスト描画のため。
- `epd7in5_V2`: EPDを制御するためのライブラリ。

## 使い方

1. `OPENAI_API_KEY`環境変数をOpenAI APIキーに設定します。
2. Whisper CLIがインストールされ、正しく構成されていることを確認します。
3. `main.py`を実行して、自動スピーカーシステムを開始します。
